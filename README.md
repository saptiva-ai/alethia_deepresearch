# Aletheia Deep Research

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/Docker-20.10+-blue.svg)](https://www.docker.com/)
[![Tests](https://img.shields.io/badge/tests-117%20passing-green.svg)](.)

**Plataforma de investigaci√≥n profunda asistida por IA** que utiliza el patr√≥n de investigaci√≥n iterativa con agentes inteligentes.

---

## ¬øQu√© es Aletheia?

Aletheia ejecuta investigaciones profundas autom√°ticas usando:
- **Planificaci√≥n inteligente** - Descompone queries complejas en sub-tareas
- **Investigaci√≥n paralela** - Ejecuta m√∫ltiples b√∫squedas simult√°neamente
- **Evaluaci√≥n iterativa** - Analiza completitud y refina autom√°ticamente
- **Reportes profesionales** - Genera markdown con evidencias y citas

**Ejemplo:**
```bash
Query: "Latest AI trends 2025"
‚Üí Plan autom√°tico con 5 sub-tareas
‚Üí 15 evidencias recolectadas de fuentes verificadas
‚Üí 2 iteraciones de refinamiento
‚Üí Reporte markdown completo en ~90 segundos
```

---

## Arquitectura

```mermaid
graph TB
    subgraph Client["Cliente"]
        HTTP[HTTP REST API]
        WS[WebSocket]
    end

    subgraph API["FastAPI Application"]
        Router[API Router]
        BG[Background Tasks]
        PM[Progress Manager]
    end

    subgraph Domain["Domain Services"]
        Planner[Planner Service<br/>Saptiva Ops]
        Researcher[Researcher Service<br/>Saptiva Ops]
        Evaluator[Evaluator Service<br/>Saptiva Ops]
        Writer[Writer Service<br/>Saptiva Cortex]
        Orchestrator[Iterative Research<br/>Orchestrator]
    end

    subgraph Adapters["Adapters"]
        Saptiva[Saptiva AI Client<br/>LLM Models]
        Tavily[Tavily Search<br/>Web Search API]
        Mongo[(MongoDB<br/>Tasks, Reports, Logs)]
        Telemetry[OpenTelemetry<br/>Tracing & Events]
    end

    HTTP --> Router
    WS --> PM
    Router --> BG
    BG --> Orchestrator
    PM -.->|Real-time updates| WS

    Orchestrator --> Planner
    Orchestrator --> Researcher
    Orchestrator --> Evaluator
    Orchestrator --> Writer

    Planner --> Saptiva
    Researcher --> Saptiva
    Researcher --> Tavily
    Evaluator --> Saptiva
    Writer --> Saptiva

    Orchestrator --> Mongo
    Orchestrator --> PM
    Orchestrator --> Telemetry

    style Domain fill:#e1f5ff
    style Adapters fill:#fff4e1
    style API fill:#f0e1ff
```

**Flujo de Deep Research:**
1. Cliente env√≠a query v√≠a HTTP POST
2. API crea tarea y la ejecuta en background
3. Orchestrator coordina el ciclo iterativo:
   - Planner descompone query en sub-tareas
   - Researcher ejecuta b√∫squedas en paralelo
   - Evaluator analiza completitud y genera refinamientos
   - Writer sintetiza reporte final
4. Progress Manager env√≠a updates en tiempo real v√≠a WebSocket
5. MongoDB persiste tareas, reportes y logs

---

## Inicio R√°pido (5 minutos)

### 1. Requisitos Previos

- **Python 3.11+** (requerido)
- **Docker + Docker Compose** (recomendado)
- **API Keys:** [Saptiva AI](https://saptiva.ai) + [Tavily Search](https://tavily.com)

```bash
# Verificar Python
python3.11 --version
# Debe mostrar: Python 3.11.x o superior
```

---

### 2. Instalaci√≥n

```bash
# Clonar repositorio
git clone https://github.com/saptiva-ai/alethia_deepresearch.git
cd alethia_deepresearch

# Crear entorno virtual
python3.11 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# Windows: .venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

---

### 3. Configuraci√≥n

```bash
# Copiar archivo de ejemplo
cp .env.example .env

# Editar con tus API keys
nano .env
```

**Configuraci√≥n m√≠nima en `.env`:**
```bash
# REQUERIDO
SAPTIVA_API_KEY=tu_clave_saptiva_aqui
TAVILY_API_KEY=tu_clave_tavily_aqui

# OPCIONAL (usa Docker Compose para MongoDB autom√°tico)
MONGODB_URL=mongodb://aletheia:aletheia_password@localhost:27018/aletheia?authSource=admin
```

---

### 4. Iniciar Sistema

**Con Docker (Recomendado):**
```bash
# Inicia API + MongoDB en contenedores
docker compose up -d

# Verificar
docker ps  # Debe mostrar: aletheia-api y aletheia-mongodb
curl http://localhost:8000/health
```

**Sin Docker (Modo Local):**
```bash
# Solo la API, sin MongoDB (in-memory)
uvicorn apps.api.main:app --reload --host 0.0.0.0 --port 8000
```

---

## üìñ Ejemplos de Uso

### Ejemplo 1: Investigaci√≥n Simple con cURL

```bash
# 1. Iniciar investigaci√≥n
curl -X POST http://localhost:8000/research \
  -H "Content-Type: application/json" \
  -d '{"query": "Python best practices 2025"}'

# Response:
# {
#   "task_id": "abc-123-def-456",
#   "status": "accepted",
#   "details": "Research task accepted. Use /tasks/{task_id}/status to monitor progress."
# }

# 2. Monitorear status
curl "http://localhost:8000/tasks/abc-123-def-456/status"

# 3. Obtener reporte cuando status=completed
curl "http://localhost:8000/reports/abc-123-def-456" | jq -r '.report_md' > report.md
```

---

### Ejemplo 2: Deep Research con cURL

```bash
# 1. Iniciar deep research con par√°metros avanzados
curl -X POST http://localhost:8000/deep-research \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Impact of AI on software development: productivity, job market, and best practices",
    "max_iterations": 3,
    "min_completion_score": 0.80,
    "budget": 150
  }'

# Response:
# {
#   "task_id": "xyz-789-uvw-012",
#   "status": "accepted",
#   "details": "Deep research task accepted with parallel processing. Configuration: 3 iterations, 0.8 min score."
# }

# 2. Monitorear progreso
watch -n 5 "curl -s 'http://localhost:8000/tasks/xyz-789-uvw-012/status' | jq"

# 3. Obtener reporte completo
curl "http://localhost:8000/deep-research/xyz-789-uvw-012" | jq '.report_md' -r > deep_report.md

# 4. Ver m√©tricas de calidad
curl "http://localhost:8000/deep-research/xyz-789-uvw-012" | jq '.quality_metrics'
```

**Par√°metros de Deep Research:**
- `max_iterations` (1-5): N√∫mero m√°ximo de iteraciones de refinamiento
- `min_completion_score` (0.5-1.0): Score m√≠nimo para considerar completa la investigaci√≥n
- `budget` (50-300): N√∫mero m√°ximo de evidencias a recolectar

---

### Ejemplo 3: WebSocket en Tiempo Real (JavaScript)

```javascript
// Conectar al WebSocket para recibir updates en tiempo real
const taskId = 'xyz-789-uvw-012';
const ws = new WebSocket(`ws://localhost:8000/ws/progress/${taskId}`);

ws.onopen = () => {
  console.log('WebSocket conectado');
};

ws.onmessage = (event) => {
  const update = JSON.parse(event.data);

  // Formato del mensaje:
  // {
  //   "task_id": "xyz-789-uvw-012",
  //   "timestamp": "2025-10-23T12:34:56.789Z",
  //   "event_type": "evidence",  // started, planning, iteration, evidence, evaluation, completed
  //   "message": "Collected 5 new evidence items (total: 12)",
  //   "data": {
  //     "new_evidence": 5,
  //     "total_evidence": 12,
  //     "iteration": 2
  //   }
  // }

  console.log(`[${update.event_type}] ${update.message}`);

  if (update.data) {
    console.log('Data:', update.data);
  }

  // Actualizar UI seg√∫n el tipo de evento
  switch (update.event_type) {
    case 'started':
      showStatus('Investigaci√≥n iniciada...');
      break;
    case 'planning':
      showStatus(`Plan creado con ${update.data.subtask_count} sub-tareas`);
      break;
    case 'iteration':
      showStatus(`Iteraci√≥n ${update.data.iteration}/${update.data.max_iterations}`);
      break;
    case 'evidence':
      updateProgress(update.data.total_evidence);
      break;
    case 'evaluation':
      showScore(update.data.score, update.data.level);
      break;
    case 'completed':
      showSuccess('¬°Investigaci√≥n completada!');
      downloadReport(taskId);
      ws.close();
      break;
    case 'failed':
      showError('La investigaci√≥n fall√≥');
      ws.close();
      break;
  }
};

ws.onerror = (error) => {
  console.error('WebSocket error:', error);
};

ws.onclose = () => {
  console.log('WebSocket cerrado');
};

// Opcional: enviar pings peri√≥dicos para mantener conexi√≥n
setInterval(() => {
  if (ws.readyState === WebSocket.OPEN) {
    ws.send('ping');
  }
}, 20000);
```

---

### Ejemplo 4: WebSocket en Tiempo Real (Python)

```python
#!/usr/bin/env python3
"""Monitoreo de deep research con WebSocket."""
import asyncio
import json
import websockets
import requests

async def monitor_research(task_id: str):
    """Monitorea el progreso de una investigaci√≥n en tiempo real."""
    ws_url = f"ws://localhost:8000/ws/progress/{task_id}"

    print(f"üì° Conectando a WebSocket: {ws_url}")

    try:
        async with websockets.connect(ws_url, ping_interval=20) as websocket:
            print("WebSocket conectado - recibiendo actualizaciones...\n")

            while True:
                try:
                    message = await asyncio.wait_for(websocket.recv(), timeout=30)
                    update = json.loads(message)

                    # Formatear output
                    event_icons = {
                        "started": "üöÄ",
                        "planning": "üìã",
                        "iteration": "üîÑ",
                        "evidence": "üîç",
                        "evaluation": "üìä",
                        "gap_analysis": "üéØ",
                        "refinement": "üîß",
                        "report_generation": "üìù",
                        "completed": "‚úÖ",
                        "failed": "‚ùå"
                    }

                    icon = event_icons.get(update["event_type"], "üìå")
                    print(f"{icon} [{update['event_type']}] {update['message']}")

                    # Mostrar data adicional si existe
                    if update.get("data"):
                        data = update["data"]
                        if "iteration" in data and "max_iterations" in data:
                            print(f"   ‚Üí Iteraci√≥n: {data['iteration']}/{data['max_iterations']}")
                        if "total_evidence" in data:
                            print(f"   ‚Üí Evidencias totales: {data['total_evidence']}")
                        if "score" in data:
                            print(f"   ‚Üí Score: {data['score']:.2%} ({data['level']})")

                    print()  # L√≠nea en blanco

                    # Salir si complet√≥ o fall√≥
                    if update["event_type"] in ["completed", "failed"]:
                        break

                except asyncio.TimeoutError:
                    # Enviar ping para mantener conexi√≥n
                    await websocket.send("ping")

    except websockets.exceptions.WebSocketException as e:
        print(f"Error de WebSocket: {e}")
    except Exception as e:
        print(f"Error inesperado: {e}")

def start_deep_research(query: str) -> str:
    """Inicia una deep research y retorna el task_id."""
    response = requests.post(
        "http://localhost:8000/deep-research",
        json={
            "query": query,
            "max_iterations": 3,
            "min_completion_score": 0.75,
            "budget": 100
        },
        timeout=10
    )
    response.raise_for_status()
    return response.json()["task_id"]

async def main():
    query = "Latest trends in AI-powered code generation 2025"

    print(f"üî¨ Iniciando deep research: {query}\n")

    # Iniciar investigaci√≥n
    task_id = start_deep_research(query)
    print(f"Task ID: {task_id}\n")

    # Monitorear progreso
    await monitor_research(task_id)

    print(f"\nDescargando reporte...")

    # Obtener reporte
    response = requests.get(f"http://localhost:8000/deep-research/{task_id}")
    report_data = response.json()

    # Guardar reporte
    if report_data.get("status") == "completed":
        with open(f"report_{task_id[:8]}.md", "w") as f:
            f.write(report_data["report_md"])
        print(f"Reporte guardado: report_{task_id[:8]}.md")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## Features Principales

### 1. Investigaci√≥n Simple (`POST /research`)
- B√∫squeda web autom√°tica con Tavily
- Generaci√≥n de reporte markdown
- **Tiempo:** ~30-60 segundos

### 2. Deep Research (`POST /deep-research`)
- **Iteraciones m√∫ltiples** (1-5 configurables)
- **Evaluaci√≥n autom√°tica** de completitud (score 0-1)
- **Refinamiento inteligente** - Identifica gaps y genera nuevas queries
- **Procesamiento paralelo** - Sub-tareas ejecutadas concurrentemente
- **Tiempo:** ~2-5 minutos

### 3. WebSocket en Tiempo Real (`WS /ws/progress/{task_id}`)
- Updates en tiempo real durante la investigaci√≥n
- Eventos: `started`, `planning`, `iteration`, `evidence`, `evaluation`, `completed`
- Conexi√≥n persistente con keepalive autom√°tico

### 4. Persistencia con MongoDB
- **Tasks:** Estado y m√©tricas de investigaciones
- **Reports:** Reportes markdown completos con metadata
- **Logs:** Historial de eventos y errores
- **Fallback:** Modo in-memory si MongoDB no est√° disponible

---

## Testing

```bash
# Unit tests (117/117 passing)
pytest tests/unit/ -v

# Integration tests
pytest tests/integration/ -v

# Con coverage
pytest tests/unit/ --cov=. --cov-report=html

# Verificaci√≥n completa del sistema
python tools/verify_system.py
```

**Resultados actuales:**
- **117 tests passing** (100%)
-  **Coverage: 55.60%** (supera el 50% requerido)

---

## Estructura del Proyecto

```
alethia_deepresearch/
‚îú‚îÄ‚îÄ apps/api/              # FastAPI application
‚îÇ   ‚îî‚îÄ‚îÄ main.py           # Endpoints REST + WebSocket
‚îú‚îÄ‚îÄ domain/               # Business logic
‚îÇ   ‚îú‚îÄ‚îÄ models/           # Evidence, Plan, Evaluation
‚îÇ   ‚îî‚îÄ‚îÄ services/         # Planner, Researcher, Evaluator, Writer
‚îÇ       ‚îî‚îÄ‚îÄ iterative_research_svc.py  # Orchestrator principal
‚îú‚îÄ‚îÄ adapters/             # External integrations
‚îÇ   ‚îú‚îÄ‚îÄ mongodb/          # MongoDB adapter (Motor async)
‚îÇ   ‚îú‚îÄ‚îÄ saptiva_model/    # Saptiva AI client
‚îÇ   ‚îú‚îÄ‚îÄ tavily_search/    # Tavily search client
‚îÇ   ‚îú‚îÄ‚îÄ websocket/        # WebSocket progress manager
‚îÇ   ‚îî‚îÄ‚îÄ telemetry/        # OpenTelemetry tracing
‚îú‚îÄ‚îÄ ports/                # Interfaces (DatabasePort)
‚îú‚îÄ‚îÄ tests/                # Unit & integration tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/            # 116 tests passing
‚îÇ   ‚îî‚îÄ‚îÄ integration/     # API + MongoDB tests
‚îú‚îÄ‚îÄ examples/             # Example scripts
‚îÇ   ‚îú‚îÄ‚îÄ simple_research.py
‚îÇ   ‚îî‚îÄ‚îÄ deep_research.py
‚îú‚îÄ‚îÄ tools/                # Utilities
‚îÇ   ‚îî‚îÄ‚îÄ verify_system.py  # System verification
‚îú‚îÄ‚îÄ docs/                 # Documentation
‚îú‚îÄ‚îÄ docker-compose.yml    # Docker orchestration
‚îî‚îÄ‚îÄ README.md            # Este archivo
```

---

## Configuraci√≥n Avanzada

### Variables de Entorno Completas

```bash
# === Saptiva AI (Requerido) ===
SAPTIVA_API_KEY=your_key
SAPTIVA_BASE_URL=https://api.saptiva.com/v1
SAPTIVA_MODEL_PLANNER=Saptiva Ops
SAPTIVA_MODEL_RESEARCHER=Saptiva Ops
SAPTIVA_MODEL_WRITER=Saptiva Cortex

# === Tavily Search (Requerido) ===
TAVILY_API_KEY=your_key

# === MongoDB (Opcional) ===
MONGODB_URL=mongodb://user:pass@host:port/db?authSource=admin
MONGODB_DATABASE=aletheia
MONGO_ROOT_USERNAME=aletheia
MONGO_ROOT_PASSWORD=aletheia_password

# === Application ===
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=INFO
API_HOST=0.0.0.0
API_PORT=8000

# === Vector Storage (Opcional) ===
VECTOR_BACKEND=none  # none | weaviate
```

### Par√°metros de Deep Research

```json
{
  "query": "Your research question",
  "max_iterations": 3,              // 1-5: N√∫mero de iteraciones
  "min_completion_score": 0.75,     // 0.5-1.0: Score m√≠nimo para completar
  "budget": 100                     // 50-300: L√≠mite de evidencias
}
```

**Completion Levels:**
- `comprehensive` (0.9-1.0): Investigaci√≥n completa y profunda
- `substantial` (0.75-0.89): Investigaci√≥n s√≥lida con cobertura amplia
- `partial` (0.5-0.74): Investigaci√≥n b√°sica con gaps
- `insufficient` (0-0.49): Investigaci√≥n insuficiente

---

## Deployment

### Docker Compose (Producci√≥n)

```bash
# Build y start
docker compose up -d

# Logs
docker compose logs -f api

# Restart con nuevos cambios
docker compose build api
docker compose up -d api

# Stop
docker compose down
```

### Health Checks

```bash
# API health
curl http://localhost:8000/health

# Response esperado:
# {
#   "status": "healthy",
#   "api_keys": {
#     "saptiva": true,
#     "tavily": true
#   },
#   "mongodb": "connected",
#   "version": "0.2.0"
# }
```

---

## Soluci√≥n de Problemas

### Error: "Python version too old"
```bash
# Ubuntu/Debian
sudo apt update && sudo apt install python3.11 python3.11-venv

# macOS
brew install python@3.11

# Verificar
python3.11 --version
```

### Error: "API keys not configured"
```bash
# Verifica tu archivo .env
cat .env | grep -E "SAPTIVA_API_KEY|TAVILY_API_KEY"

# Las keys NO deben estar vac√≠as
```

### MongoDB connection issues
```bash
# Verifica que MongoDB est√© corriendo
docker ps | grep mongo

# Reinicia MongoDB
docker compose restart mongodb

# Check logs
docker logs aletheia-mongodb
```

### WebSocket timeout
```bash
# Aumenta el timeout en el cliente
# Python:
await websocket.recv(timeout=60)

# JavaScript:
// El navegador maneja timeouts autom√°ticamente
// Env√≠a pings cada 20s para mantener conexi√≥n
setInterval(() => ws.send('ping'), 20000);
```

---

## Documentaci√≥n Adicional

- **[IMPLEMENTATION_SUMMARY.md](docs/IMPLEMENTATION_SUMMARY.md)** - Detalles de implementaci√≥n
- **[Testing Guide](docs/testing/TESTING_GUIDE.md)** - Gu√≠a completa de testing
- **[API Docs](http://localhost:8000/docs)** - Swagger UI interactivo
- **[Changelog](docs/archive/)** - Historial de cambios

---

## Contribuciones

Las contribuciones son bienvenidas! Por favor:

1. Fork el repositorio
2. Crea una branch (`git checkout -b feature/amazing-feature`)
3. Commit tus cambios (`git commit -m 'Add amazing feature'`)
4. Push a la branch (`git push origin feature/amazing-feature`)
5. Abre un Pull Request

**Antes de contribuir:**
- Ejecuta tests: `pytest tests/unit/ -v`
- Verifica linting: `ruff check .`
- Actualiza documentaci√≥n si es necesario

---

## Agradecimientos

- **[Saptiva AI](https://saptiva.ai)** - Modelos de lenguaje
- **[Tavily](https://tavily.com)** - API de b√∫squeda web
- **[Together AI](https://together.ai)** - Inspiraci√≥n del patr√≥n de investigaci√≥n iterativa

---

## Soporte

- **Issues:** [GitHub Issues](https://github.com/saptiva-ai/alethia_deepresearch/issues)
- **Documentaci√≥n:** [docs/](docs/)
- **Email:** support@saptiva.ai

---

**Hecho con ‚ù§Ô∏è by Saptiva AI Team**


## License

```
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   Copyright 2025 Saptiva Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
```

For the complete license text, see the [LICENSE](LICENSE) file in the repository root.
