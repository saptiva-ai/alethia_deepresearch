# Aletheia (·ºÄŒªŒÆŒ∏ŒµŒπŒ± ‚Äì desocultamiento de la verdad)

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Docker](https://img.shields.io/badge/Docker-20.10+-blue.svg)](https://www.docker.com/)
[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

Aletheia es una plataforma de investigaci√≥n asistida por agentes que separa claramente el
*Dominio* de la orquestaci√≥n y de las integraciones externas. El objetivo del repositorio es
ofrecer un pipeline reproducible para planear, ejecutar y sintetizar investigaciones
aprovechando modelos de lenguaje de Saptiva y fuentes externas (Tavily, documentos locales, etc.).

> **Estado:** ‚úÖ **En producci√≥n** - API completamente operativa, configuraci√≥n minimalista, deployment simplificado.

> üìù **¬øVienes de una versi√≥n anterior?** El proyecto ha sido simplificado para setup instant√°neo. Ver [SIMPLIFICATION.md](SIMPLIFICATION.md) para detalles de los cambios y gu√≠a de migraci√≥n.

---

## üÜï ¬øPrimera vez usando Aletheia?

üëâ **Lee primero [QUICKSTART.md](QUICKSTART.md)** - Gu√≠a paso a paso de 5 minutos que te llevar√° de cero a tu primera investigaci√≥n funcionando.

El QUICKSTART incluye:
- ‚úÖ Setup completo paso a paso
- ‚úÖ Verificaci√≥n autom√°tica del sistema
- ‚úÖ Ejemplos de uso inmediatos
- ‚úÖ Soluci√≥n de problemas comunes

---

## üéØ Configuraci√≥n Minimalista

Este proyecto est√° optimizado para un **setup simple y directo**:

‚úÖ **Solo 2 API Keys requeridas**: Saptiva + Tavily
‚úÖ **MongoDB integrado**: Almacenamiento persistente para tareas, reportes y logs
‚úÖ **Python 3.11+ como √∫nico requisito** del sistema (modo local)
‚úÖ **Docker opcional**: Funciona localmente sin contenedores
‚úÖ **Zero config**: Valores por defecto listos para producci√≥n

**Tiempo de setup:** < 5 minutos desde cero

### üíæ Almacenamiento de Datos

- **Con MongoDB (Recomendado)**: Persistencia completa de tareas, reportes y logs
- **Sin MongoDB (Fallback)**: Almacenamiento en memoria (se pierde al reiniciar)
- **Producci√≥n**: MongoDB obligatorio para multi-worker y persistencia

---

## üöÄ Enlaces R√°pidos

- **[‚ö° QUICKSTART.md](QUICKSTART.md)**: ¬°Empieza aqu√≠! Gu√≠a de 5 minutos para nuevos usuarios
- **[Configuraci√≥n R√°pida](#-configuraci√≥n-r√°pida)**: Setup en < 5 minutos
- **[Verificar Sistema](#-verificar-instalaci√≥n)**: Script de prueba completo
- **[API Docs](http://localhost:8000/docs)**: Swagger UI interactivo (cuando el servidor est√© corriendo)
- **[Health Check](http://localhost:8000/health)**: Verificar estado del sistema
- **[Deployment](#-deployment)**: Gu√≠as de despliegue
- **[Arquitectura](#-arquitectura)**: Dise√±o del sistema
- **[SIMPLIFICATION.md](SIMPLIFICATION.md)**: Gu√≠a de la configuraci√≥n minimalista

---

## üì¶ Qu√© incluye el repositorio

- **`apps/api`**: Aplicaci√≥n FastAPI que expone endpoints de investigaci√≥n y salud
- **`domain`**: Reglas de negocio (planificaci√≥n, evaluaci√≥n, orquestaci√≥n iterativa y modelos)
- **`adapters`**: Integraciones concretas (Saptiva, Tavily, extracci√≥n de documentos, telemetr√≠a, almacenamiento vectorial, etc.)
- **`ports`**: Interfaces que definen contratos entre el dominio y los adapters
- **`infra`**: Infraestructura como c√≥digo (Docker, Kubernetes)
- **`scripts`**: Scripts de deployment y utilidades de desarrollo
- **`tests`**: Suites unitarias e integrales (99 tests, cobertura 23%+)
- **`docs`**: Material de referencia y diagramas adicionales

---

## üõ† Requisitos M√≠nimos

### Esenciales (Requeridos)
- **Python 3.11+** ‚ö†Ô∏è **REQUERIDO** - El proyecto usa sintaxis moderna de Python
- **pip** y **virtualenv** para gesti√≥n de dependencias
- **API Keys**:
  - Saptiva AI: [Obtener key](https://saptiva.ai)
  - Tavily Search: [Obtener key](https://tavily.com)

### Opcionales (No requeridos por defecto)
- **Docker + Docker Compose** - Para deployment con contenedores y MongoDB integrado
- **MongoDB 7.0+** - Para almacenamiento persistente (recomendado para producci√≥n)
- **Weaviate** - Solo si activas vector database (`VECTOR_BACKEND=weaviate`)
- **Tesseract OCR** - Solo para procesamiento OCR de im√°genes
- **Jaeger** - Solo para trazabilidad distribuida avanzada

> **Nota importante**: El sistema funciona completamente sin servicios externos para desarrollo. Para producci√≥n se recomienda MongoDB para persistencia de datos.

### Verificar Python 3.11

‚ö†Ô∏è **IMPORTANTE**: Verifica tu versi√≥n de Python antes de continuar:

```bash
python3.11 --version  # Debe mostrar Python 3.11.x o superior
```

**Si no tienes Python 3.11:**

```bash
# Ubuntu/Debian
sudo apt update && sudo apt install python3.11 python3.11-venv python3.11-dev

# macOS (Homebrew)
brew install python@3.11
```

---

## ‚ö° Configuraci√≥n R√°pida

Existen dos modos de configuraci√≥n:

- **üöÄ Modo Contenedor (Recomendado)**: Incluye MongoDB, f√°cil deployment, producci√≥n ready
- **üíª Modo Local**: Desarrollo r√°pido sin Docker, usa almacenamiento en memoria

### Opci√≥n A: Modo Contenedor (Con MongoDB) üöÄ

**Ventajas:**
- ‚úÖ MongoDB integrado para persistencia
- ‚úÖ Configuraci√≥n lista para producci√≥n
- ‚úÖ F√°cil escalamiento
- ‚úÖ Datos persisten entre reinicios

```bash
# 1. Clonar repositorio
git clone https://github.com/saptiva-ai/alethia_deepresearch.git
cd alethia_deepresearch

# 2. Configurar variables de entorno
cp .env.example .env
# Edita .env con tus API keys (Saptiva + Tavily)

# 3. Iniciar servicios con Docker Compose
docker-compose up -d

# 4. Verificar estado
curl http://localhost:8000/health
docker logs aletheia-api
docker logs aletheia-mongodb

# 5. Ver documentaci√≥n interactiva
# Abre en tu navegador: http://localhost:8000/docs
```

**Servicios levantados:**
- API: http://localhost:8000 (contenedor `aletheia-api`)
- MongoDB: localhost:27018 (contenedor `aletheia-mongodb`)
- Vol√∫menes persistentes: `mongodb_data`, `mongodb_config`

**Comandos √∫tiles:**
```bash
# Ver logs en tiempo real
docker-compose logs -f api

# Reiniciar servicios
docker-compose restart

# Detener servicios
docker-compose down

# Detener y eliminar datos
docker-compose down -v
```

---

### Opci√≥n B: Modo Local (Sin Docker) üíª

**Ventajas:**
- ‚úÖ Setup m√°s r√°pido
- ‚úÖ No requiere Docker
- ‚úÖ Ideal para desarrollo
- ‚ö†Ô∏è Sin persistencia de datos (usa memoria)

### 1. Clonar y configurar entorno

‚ö†Ô∏è **IMPORTANTE: Usa `python3.11` expl√≠citamente en todos los comandos**

```bash
git clone https://github.com/saptiva-ai/alethia_deepresearch.git
cd alethia_deepresearch

# Crear entorno virtual con Python 3.11
python3.11 -m venv .venv

# Activar entorno virtual
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Verificar que est√°s usando Python 3.11
python --version  # Debe mostrar Python 3.11.x
```

### 2. Instalar dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
pip install -e .[dev]  # Incluye herramientas de desarrollo
```

### 3. Configurar variables de entorno

```bash
cp .env.example .env
```

Edita `.env` con tus API keys:

```bash
# === REQUERIDO ===
SAPTIVA_API_KEY=tu_clave_saptiva_aqui
TAVILY_API_KEY=tu_clave_tavily_aqui

# === Configuraci√≥n predeterminada (ya configurada) ===
SAPTIVA_BASE_URL=https://api.saptiva.com/v1
VECTOR_BACKEND=none
ENVIRONMENT=development

# === MongoDB (Opcional - Solo para persistencia local) ===
# Descomenta estas l√≠neas solo si tienes MongoDB instalado localmente
# MONGODB_URL=mongodb://localhost:27017
# MONGODB_DATABASE=aletheia

# Nota: Las l√≠neas de Docker Compose (mongodb://...@mongodb:27017)
# NO funcionan en modo local. Solo usar en Docker Compose.
```

**Notas:**
- Los dem√°s valores ya tienen defaults apropiados
- Solo necesitas las API keys para comenzar
- MongoDB es opcional en modo local (usa almacenamiento en memoria si no est√° configurado)

### 4. Verificar configuraci√≥n (opcional pero recomendado)

```bash
# Ejecutar script de verificaci√≥n
./scripts/check_python_version.sh
```

### 5. Ejecutar la API

```bash
# Aseg√∫rate de que el entorno virtual est√© activado
python --version  # Debe mostrar Python 3.11.x

# Ejecutar el servidor
uvicorn apps.api.main:app --reload --port 8000
```

üéâ **API disponible en:** http://localhost:8000/docs

**Notas importantes:**
- ‚úÖ El servidor usa **modo minimalista** por defecto (sin Weaviate, sin servicios externos)
- ‚úÖ Si obtienes errores de sintaxis como `TypeError: unsupported operand type(s) for |`, est√°s usando Python < 3.10
- ‚úÖ Los warnings de Pydantic son normales y no afectan la funcionalidad

### 6. Verificar Instalaci√≥n

Ejecuta el script de verificaci√≥n completo del sistema:

```bash
python tools/verify_system.py
```

Este script verifica:
- ‚úÖ Variables de entorno configuradas correctamente
- ‚úÖ API corriendo y saludable
- ‚úÖ Endpoint `/research` funcionando (investigaci√≥n simple)
- ‚úÖ Endpoint `/deep-research` funcionando (investigaci√≥n profunda con WebSocket)
- ‚úÖ Guardado de reportes en MongoDB (si est√° configurado)
- ‚úÖ Trazabilidad completa del sistema

**Salida esperada:**
```
üîç VERIFICACI√ìN COMPLETA DEL SISTEMA ALETHEIA

1Ô∏è‚É£  VERIFICACI√ìN DE VARIABLES DE ENTORNO
‚úÖ PASS - SAPTIVA_API_KEY configurada
‚úÖ PASS - TAVILY_API_KEY configurada
‚úÖ PASS - MONGODB_URL configurada

2Ô∏è‚É£  VERIFICACI√ìN DE API
‚úÖ PASS - API Health Check
‚úÖ PASS - API Version

3Ô∏è‚É£  VERIFICACI√ìN DE INVESTIGACI√ìN SIMPLE (/research)
‚úÖ PASS - Iniciar Research
‚úÖ PASS - Research Completado
‚úÖ PASS - Reporte Generado
‚úÖ PASS - Fuentes Documentadas

4Ô∏è‚É£  VERIFICACI√ìN DE DEEP RESEARCH CON WEBSOCKET
‚úÖ PASS - Iniciar Deep Research
‚úÖ PASS - WebSocket Connection
‚úÖ PASS - Deep Research Completado
‚úÖ PASS - Reporte Generado
‚úÖ PASS - M√©tricas de Calidad

5Ô∏è‚É£  VERIFICACI√ìN DE ALMACENAMIENTO (MONGODB)
‚úÖ PASS - Conexi√≥n a MongoDB
‚úÖ PASS - Collection: tasks
‚úÖ PASS - Collection: reports

üìã RESUMEN FINAL
Tests ejecutados: 20
‚úÖ Pasados: 20
‚ùå Fallados: 0

üéâ ¬°TODOS LOS TESTS PASARON! El sistema est√° funcionando correctamente.
```

Si todos los tests pasan, **¬°est√°s listo para usar Aletheia!** üöÄ

---

## üß™ Pruebas y Calidad de C√≥digo

El proyecto mantiene est√°ndares profesionales con CI/CD automatizado:

### Ejecutar verificaciones localmente

```bash
# Linting y formato
ruff check .
ruff check . --fix  # Corregir problemas autom√°ticamente

# Type checking
mypy domain/models --ignore-missing-imports

# Tests unitarios (99 tests, sin servicios externos)
pytest tests/unit/ -v --cov=domain --cov=adapters --cov=apps --cov-report=term-missing

# Tests de integraci√≥n (requiere configurar API keys)
pytest tests/integration/ -v
```

### Pipeline CI/CD Automatizado

El repositorio incluye verificaciones completas en cada push:

- ‚úÖ **Linting**: Ruff para calidad de c√≥digo
- ‚úÖ **Type checking**: MyPy para validaci√≥n de tipos
- ‚úÖ **Testing**: 99 unit tests con 23%+ cobertura
- ‚úÖ **Security**: Bandit + Safety para an√°lisis de seguridad
- ‚úÖ **Build**: Docker multi-stage optimizado
- ‚úÖ **Deploy**: Automatizaci√≥n a staging/producci√≥n

Ver `.github/workflows/ci.yml` para configuraci√≥n completa.

---

## üöÄ Deployment

### Opci√≥n 1: Docker Compose (Recomendado para producci√≥n) ‚úÖ

El m√©todo m√°s simple y r√°pido:

```bash
# 1. Configurar variables de entorno
cp .env.example .env
# Edita .env con tus API keys (Saptiva + Tavily)

# 2. Iniciar el servicio
docker-compose up -d

# 3. Verificar estado
curl http://localhost:8000/health
```

**Acceso:**
- API: http://localhost:8000
- Documentaci√≥n interactiva: http://localhost:8000/docs
- Redoc: http://localhost:8000/redoc

### Opci√≥n 2: Docker Build Manual

```bash
# Build
docker build -t aletheia-api .

# Run
docker run -d \
  --name aletheia-api \
  -p 8000:8000 \
  --env-file .env \
  aletheia-api
```

### Opci√≥n 3: Servidor Directo (SSH)

Para servidores con acceso SSH:

```bash
# En el servidor remoto
git clone https://github.com/saptiva-ai/alethia_deepresearch.git
cd alethia_deepresearch
python3.11 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
# Edita .env con tus keys

# Ejecutar con systemd o supervisord
uvicorn apps.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Configuraci√≥n de Producci√≥n

Ajustes recomendados para entornos de producci√≥n:

```bash
# === API Keys (REQUERIDAS) ===
SAPTIVA_API_KEY=your_production_key
TAVILY_API_KEY=your_production_key

# === Configuraci√≥n de producci√≥n ===
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=WARNING
API_RELOAD=false

# === Servicios opcionales (deshabilitados por defecto) ===
VECTOR_BACKEND=none  # Cambiar a 'weaviate' solo si lo necesitas
```

**Nota**: El sistema funciona perfectamente sin servicios adicionales (Weaviate, Jaeger, etc.).

---

## üì° API Endpoints

### Core Research Endpoints

| Endpoint | Method | Descripci√≥n | Tiempo estimado |
|----------|--------|-------------|-----------------|
| `/health` | GET | Health check con status de APIs | < 1s |
| `/research` | POST | Investigaci√≥n simple optimizada | 30-60s |
| `/deep-research` | POST | Investigaci√≥n profunda iterativa | 2-5 min |
| `/tasks/{task_id}/status` | GET | Estado de tarea en curso | < 1s |
| `/reports/{task_id}` | GET | Reporte final generado | < 1s |
| `/traces/{task_id}` | GET | Trazas de telemetr√≠a | < 1s |
| `/ws/progress/{task_id}` | WebSocket | **Actualizaciones en tiempo real** | Streaming |

### üöÄ Gu√≠a de Inicio R√°pido

#### 1. Verificar que el sistema est√© funcionando

```bash
# Health check - verifica que la API est√© corriendo
curl http://localhost:8000/health

# Respuesta esperada
{
  "status": "healthy",
  "service": "Aletheia Deep Research API",
  "version": "0.2.0",
  "api_keys": {
    "saptiva_available": true,
    "tavily_available": true
  }
}
```

#### 2. Investigaci√≥n Simple (Recomendado para comenzar)

**Caracter√≠sticas:**
- ‚úÖ R√°pida (30-60 segundos)
- ‚úÖ Procesamiento paralelo
- ‚úÖ Ideal para consultas directas

```bash
# Iniciar investigaci√≥n
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "√öltimas tendencias en inteligencia artificial 2025"
  }'

# Respuesta
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "accepted",
  "details": "Research task has been accepted and is running..."
}

# Verificar estado (espera ~30 segundos)
curl "http://localhost:8000/tasks/550e8400-e29b-41d4-a716-446655440000/status"

# Cuando status="completed", obtener el reporte
curl "http://localhost:8000/reports/550e8400-e29b-41d4-a716-446655440000"
```

#### 3. Investigaci√≥n Profunda (Deep Research)

**Caracter√≠sticas:**
- üîÑ Iterativa con refinamiento autom√°tico
- üìä Evaluaci√≥n de completitud
- üéØ Identificaci√≥n de brechas de informaci√≥n
- ‚öôÔ∏è Par√°metros configurables
- üì° **Actualizaciones en tiempo real via WebSocket**

```bash
# Iniciar investigaci√≥n profunda
curl -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Impacto de la regulaci√≥n AI Act en startups europeas",
    "max_iterations": 3,
    "min_completion_score": 0.85,
    "budget": 200
  }'

# Respuesta
{
  "task_id": "deep-550e8400-e29b-41d4-a716-446655440000",
  "status": "accepted",
  "details": "Deep research task accepted with parallel processing..."
}

# Obtener reporte con m√©tricas de calidad
curl "http://localhost:8000/deep-research/deep-550e8400-e29b-41d4-a716-446655440000"
```

**Par√°metros de Deep Research:**

| Par√°metro | Tipo | Descripci√≥n | Default | Rango |
|-----------|------|-------------|---------|-------|
| `query` | string | Consulta de investigaci√≥n | - | Requerido |
| `max_iterations` | int | M√°ximo de iteraciones | 3 | 1-10 |
| `min_completion_score` | float | Score m√≠nimo para finalizar | 0.75 | 0.1-1.0 |
| `budget` | int | Presupuesto total | 100 | 1-5000 |

### üìã Casos de Uso Pr√°cticos

#### Caso 1: An√°lisis de Mercado

```bash
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "An√°lisis del mercado de fintech en M√©xico 2025: principales competidores, regulaci√≥n y tendencias"
  }'
```

**Tiempo estimado:** 45 segundos
**Fuentes t√≠picas:** 10-15 art√≠culos

#### Caso 2: Due Diligence Tecnol√≥gico

```bash
curl -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Evaluaci√≥n t√©cnica de frameworks de IA: PyTorch vs TensorFlow vs JAX",
    "max_iterations": 5,
    "min_completion_score": 0.90
  }'
```

**Tiempo estimado:** 4-5 minutos
**Fuentes t√≠picas:** 40-60 documentos

#### Caso 3: Investigaci√≥n Acad√©mica

```bash
curl -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Estado del arte en modelos de lenguaje multimodales: arquitecturas, benchmarks y aplicaciones",
    "max_iterations": 7,
    "budget": 300
  }'
```

**Tiempo estimado:** 6-8 minutos
**Fuentes t√≠picas:** 60-100 papers y art√≠culos

---

## üéØ Ejemplos Completos y Casos de Uso Reales

Esta secci√≥n muestra ejemplos end-to-end con queries reales, resultados esperados y mejores pr√°cticas.

### Ejemplo 1: Investigaci√≥n de Tecnolog√≠a üíª

**Escenario:** Arquitecto de software evaluando frameworks async para un nuevo proyecto.

**Query:**
```bash
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Best practices for Python async programming in 2025"
  }'
```

**Resultado Real (Probado):**
- ‚è±Ô∏è **Tiempo:** 40 segundos
- üìö **Fuentes:** 10 sources
- üìÑ **Longitud:** ~7,500 caracteres
- ‚≠ê **Calidad:** Excelente

**Estructura del Reporte:**
```markdown
# Best practices for Python async programming in 2025

## Executive Summary
Resumen conciso de 150-200 palabras con los hallazgos principales

## Key Findings
- FastAPI como framework dominante
- Asyncio integrado en Python 3.13+
- Patrones de concurrencia con sem√°foros
- Mejores pr√°cticas de error handling

## Detailed Analysis
### Understanding Asyncio's Role
[An√°lisis profundo...]

### Framework Selection
[Comparaci√≥n de frameworks...]

### Best Practices for Implementation
[Ejemplos de c√≥digo y patrones...]

## Conclusions
[Resumen de conclusiones con recomendaciones]

## Sources
[9 fuentes citadas con URLs]
```

**¬øCu√°ndo usar este tipo de investigaci√≥n?**
- Evaluaci√≥n t√©cnica r√°pida
- Comparaci√≥n de herramientas
- Learning de nuevas tecnolog√≠as
- Documentaci√≥n de arquitectura

---

### Ejemplo 2: An√°lisis de Mercado üìä

**Escenario:** Product Manager investigando competencia antes de lanzar feature.

**Query Recomendada:**
```bash
curl -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "API Gateway market leaders 2025: features, pricing, and developer experience comparison"
  }'
```

**Qu√© Esperar:**
```json
{
  "task_id": "uuid-here",
  "status": "accepted"
}
```

**Resultado Esperado:**
- Comparaci√≥n de AWS API Gateway, Kong, Tyk, Apigee
- Feature matrix
- Pricing breakdown
- Developer satisfaction scores
- Tendencias del mercado

**Pipeline Completo:**
```bash
#!/bin/bash
# Script de an√°lisis de mercado completo

# 1. Iniciar investigaci√≥n
echo "üîç Iniciando an√°lisis de mercado..."
RESPONSE=$(curl -s -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "API Gateway market leaders 2025: features, pricing, and developer experience"
  }')

TASK_ID=$(echo $RESPONSE | jq -r '.task_id')
echo "üìã Task ID: $TASK_ID"

# 2. Monitorear progreso
echo "‚è≥ Esperando completaci√≥n (30-60s)..."
for i in {1..20}; do
  STATUS=$(curl -s "http://localhost:8000/tasks/$TASK_ID/status" | jq -r '.status')
  echo "   [$i/20] Status: $STATUS"

  if [ "$STATUS" == "completed" ]; then
    break
  fi
  sleep 3
done

# 3. Obtener y guardar reporte
echo "üì• Descargando reporte..."
curl -s "http://localhost:8000/reports/$TASK_ID" | jq -r '.report_md' > "market_analysis_$(date +%Y%m%d).md"

echo "‚úÖ Reporte guardado: market_analysis_$(date +%Y%m%d).md"

# 4. Mostrar preview
echo ""
echo "üìÑ Preview del reporte:"
head -30 "market_analysis_$(date +%Y%m%d).md"
```

---

### Ejemplo 3: Due Diligence T√©cnico üîç

**Escenario:** CTO evaluando stack tecnol√≥gico de startup antes de adquisici√≥n.

**Query Deep Research:**
```bash
curl -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Technical architecture evaluation: React vs Vue vs Svelte for enterprise SaaS in 2025 - scalability, performance, hiring pool, and long-term viability",
    "max_iterations": 5,
    "min_completion_score": 0.9,
    "budget": 250
  }'
```

**Por qu√© Deep Research:**
- ‚úÖ Decisi√≥n de alto impacto
- ‚úÖ Requiere an√°lisis profundo
- ‚úÖ M√∫ltiples dimensiones (tech, hiring, costos)
- ‚úÖ Necesita alto nivel de confianza (90%+)

**Monitoreo en Tiempo Real:**
```python
# Usa el script con WebSocket
python examples/deep_research.py \
  "Technical architecture evaluation: React vs Vue vs Svelte for enterprise SaaS in 2025"
```

**Salida Esperada (Tiempo Real):**
```
üöÄ [0.1s] Starting deep research
üìã [3.2s] Research plan created with 8 sub-tasks
   ‚Ä¢ React ecosystem analysis
   ‚Ä¢ Vue ecosystem analysis
   ‚Ä¢ Svelte ecosystem analysis
   ‚Ä¢ Performance benchmarks
   ‚Ä¢ Developer hiring trends
   ‚Ä¢ Enterprise adoption rates
   ‚Ä¢ Long-term support assessment
   ‚Ä¢ Cost-benefit analysis

üîÑ [3.5s] Starting iteration 1/5
üîç [18.3s] Collected 15 evidence items (total: 15)
üìä [19.1s] Completion score: 52% (PRELIMINARY)
   ‚îî‚îÄ Gaps: hiring_data, performance_benchmarks

üîÑ [21.5s] Starting iteration 2/5
üîç [35.8s] Collected 12 evidence items (total: 27)
üìä [36.5s] Completion score: 78% (COMPREHENSIVE)
   ‚îî‚îÄ Gaps: cost_analysis

üîÑ [39.0s] Starting iteration 3/5
üîç [52.3s] Collected 8 evidence items (total: 35)
üìä [53.1s] Completion score: 91% (COMPREHENSIVE)
   ‚îî‚îÄ Threshold met! ‚úÖ

üìù [53.5s] Generating final report...
‚úÖ [62.8s] Deep research completed!

üìä Final Metrics:
   ‚Ä¢ Quality Score: 91%
   ‚Ä¢ Evidence Count: 35
   ‚Ä¢ Iterations: 3/5
   ‚Ä¢ Execution Time: 62.8s

üíæ Report saved: deep_research_Technical_architecture_20251023_014530.md
```

---

### Ejemplo 4: Investigaci√≥n Regulatoria ‚öñÔ∏è

**Escenario:** Legal team necesita an√°lisis de regulaciones GDPR + AI Act.

**Query Compleja:**
```bash
curl -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "GDPR and AI Act compliance requirements for LLM-based chatbot in healthcare: data retention, consent management, and audit trails - practical implementation guide",
    "max_iterations": 7,
    "min_completion_score": 0.95,
    "budget": 300
  }'
```

**Configuraci√≥n Explicada:**
- `max_iterations: 7` - Tema complejo, permite refinamiento extenso
- `min_completion_score: 0.95` - Alto nivel de confianza requerido (legal)
- `budget: 300` - Mayor presupuesto para m√°s fuentes

**Resultado Esperado:**
```json
{
  "status": "completed",
  "quality_metrics": {
    "completion_level": "COMPREHENSIVE",
    "quality_score": 0.95,
    "evidence_count": 65,
    "execution_time": 180.5
  },
  "research_summary": {
    "iterations": 5,
    "gaps_identified": ["practical_examples", "audit_procedures"],
    "key_findings": [
      "Consent must be explicit and granular",
      "Data retention max 24 months",
      "Audit trails required for all processing",
      "Third-party processor agreements mandatory"
    ]
  }
}
```

---

### Ejemplo 5: Competitive Intelligence üéØ

**Escenario:** Sales team preparando propuesta contra competidores espec√≠ficos.

**Pipeline Multi-Research:**
```bash
#!/bin/bash
# Investigaci√≥n paralela de 3 competidores

COMPETITORS=("Competitor_A" "Competitor_B" "Competitor_C")
declare -a TASK_IDS

echo "üöÄ Iniciando investigaci√≥n de competidores..."

# Iniciar investigaciones en paralelo
for COMP in "${COMPETITORS[@]}"; do
  RESPONSE=$(curl -s -X POST "http://localhost:8000/research" \
    -H "Content-Type: application/json" \
    -d "{\"query\": \"$COMP: product features, pricing, customer reviews, and market position 2025\"}")

  TASK_ID=$(echo $RESPONSE | jq -r '.task_id')
  TASK_IDS+=("$TASK_ID")
  echo "   üìã $COMP: $TASK_ID"
done

echo ""
echo "‚è≥ Esperando completaci√≥n de 3 investigaciones..."

# Esperar a que todas completen
sleep 45

# Descargar todos los reportes
echo "üì• Descargando reportes..."
for i in "${!TASK_IDS[@]}"; do
  COMP="${COMPETITORS[$i]}"
  TASK_ID="${TASK_IDS[$i]}"

  curl -s "http://localhost:8000/reports/$TASK_ID" | \
    jq -r '.report_md' > "competitor_${COMP}_$(date +%Y%m%d).md"

  echo "   ‚úÖ $COMP: competitor_${COMP}_$(date +%Y%m%d).md"
done

echo ""
echo "üéâ An√°lisis competitivo completado!"
echo "   Revisa los 3 reportes para crear comparativa"
```

---

### Ejemplo 6: Research + AI para Resumen Ejecutivo ü§ñ

**Escenario:** Ejecutivo necesita resumen de 1 p√°gina de investigaci√≥n de 50 p√°ginas.

**Pipeline Completo:**
```python
#!/usr/bin/env python3
"""Pipeline: Deep Research ‚Üí Reporte ‚Üí Resumen Ejecutivo"""

import requests
import time
from anthropic import Anthropic

def deep_research(query):
    """Ejecuta deep research y retorna reporte completo."""
    response = requests.post(
        "http://localhost:8000/deep-research",
        json={
            "query": query,
            "max_iterations": 5,
            "min_completion_score": 0.85
        }
    )
    task_id = response.json()["task_id"]

    # Esperar completaci√≥n
    while True:
        status = requests.get(
            f"http://localhost:8000/deep-research/{task_id}"
        ).json()

        if status["status"] == "completed":
            return status["report_md"]

        time.sleep(5)

def create_executive_summary(report, max_words=500):
    """Usa Claude para crear resumen ejecutivo."""
    client = Anthropic(api_key="your-key")

    response = client.messages.create(
        model="claude-3-5-sonnet-20241022",
        max_tokens=1024,
        messages=[{
            "role": "user",
            "content": f"""Create an executive summary (max {max_words} words) of this research report.
Focus on: key findings, recommendations, and business impact.

Report:
{report}
"""
        }]
    )

    return response.content[0].text

# Uso
query = "Market opportunity for AI code assistants in enterprise 2025"
print("üîç Starting deep research...")
full_report = deep_research(query)

print("üìÑ Generating executive summary...")
summary = create_executive_summary(full_report)

print("\n" + "="*70)
print("EXECUTIVE SUMMARY")
print("="*70)
print(summary)
```

---

## üí° Mejores Pr√°cticas por Escenario

### Research Simple (30-60s)
**Mejor para:**
- ‚úÖ Preguntas directas con respuesta conocida
- ‚úÖ Comparaciones simples
- ‚úÖ Learning de tecnolog√≠as
- ‚úÖ News y tendencias actuales

**Ejemplos de queries efectivas:**
```
‚úÖ "TypeScript best practices 2025"
‚úÖ "Redis vs Memcached performance comparison"
‚úÖ "Latest features in Python 3.13"
‚úÖ "Docker security hardening checklist"
```

**Queries a evitar:**
```
‚ùå "Tell me about programming" (muy amplio)
‚ùå "Best technology" (sin contexto)
‚ùå "How to code" (muy vago)
```

---

### Deep Research (2-8 min)
**Mejor para:**
- ‚úÖ Decisiones de alto impacto
- ‚úÖ Due diligence t√©cnico
- ‚úÖ Investigaci√≥n regulatoria
- ‚úÖ An√°lisis competitivo profundo
- ‚úÖ Research acad√©mico

**Configuraci√≥n recomendada:**

| Escenario | max_iterations | min_score | budget |
|-----------|---------------|-----------|--------|
| **Decisi√≥n r√°pida** | 3 | 0.75 | 100 |
| **An√°lisis est√°ndar** | 5 | 0.85 | 200 |
| **Due diligence** | 7 | 0.90 | 300 |
| **Investigaci√≥n legal** | 10 | 0.95 | 500 |

**Ejemplo de query efectiva:**
```json
{
  "query": "Comprehensive analysis: [Topic] - [Dimension 1], [Dimension 2], [Dimension 3] - [Specific focus]",
  "max_iterations": 5,
  "min_completion_score": 0.85
}
```

**Template de query:**
```
[Contexto] + [Pregunta espec√≠fica] + [Dimensiones de an√°lisis] + [Entregable deseado]

Ejemplo:
"For a Series B SaaS startup with 50 employees: evaluate build vs buy decision for authentication system - consider security, cost, time-to-market, and maintenance - provide ROI analysis"
```

---

## üîß Integraciones Avanzadas

### Integraci√≥n con Slack

```python
from slack_sdk import WebClient
import requests

def research_to_slack(query, channel):
    """Env√≠a resultado de investigaci√≥n a Slack."""

    # Iniciar research
    response = requests.post(
        "http://localhost:8000/research",
        json={"query": query}
    )
    task_id = response.json()["task_id"]

    # Notificar inicio
    slack = WebClient(token="your-token")
    slack.chat_postMessage(
        channel=channel,
        text=f"üîç Research iniciado: {query}\nTask ID: {task_id}"
    )

    # Monitorear y notificar completaci√≥n
    # (implementar polling o webhook)
```

### Integraci√≥n con Notion

```python
from notion_client import Client

def save_report_to_notion(task_id, notion_page_id):
    """Guarda reporte en p√°gina de Notion."""

    # Obtener reporte
    report = requests.get(
        f"http://localhost:8000/reports/{task_id}"
    ).json()

    # Guardar en Notion
    notion = Client(auth="your-token")
    notion.blocks.children.append(
        notion_page_id,
        children=[{
            "object": "block",
            "type": "paragraph",
            "paragraph": {
                "rich_text": [{
                    "type": "text",
                    "text": {"content": report["report_md"]}
                }]
            }
        }]
    )
```

---

### üì° Actualizaciones en Tiempo Real con WebSocket (Nuevo!)

El sistema ahora soporta **WebSocket** para recibir actualizaciones en tiempo real durante la investigaci√≥n profunda, eliminando la necesidad de hacer polling manual.

#### Ventajas del WebSocket:
- ‚úÖ **Feedback instant√°neo** del progreso de la investigaci√≥n
- ‚úÖ **Sin polling** - actualizaciones push autom√°ticas
- ‚úÖ **Visibilidad completa** de cada fase del proceso
- ‚úÖ **Mejor experiencia de usuario** con informaci√≥n en tiempo real

#### Tipos de Eventos:

| Evento | Descripci√≥n | Datos incluidos |
|--------|-------------|----------------|
| `started` | Investigaci√≥n iniciada | Configuraci√≥n, par√°metros |
| `planning` | Plan de investigaci√≥n creado | N√∫mero de sub-tareas |
| `iteration` | Nueva iteraci√≥n comenz√≥ | N√∫mero de iteraci√≥n |
| `evidence` | Evidencia recolectada | Cantidad nueva y total |
| `evaluation` | Score de completitud calculado | Score, nivel de completitud |
| `gap_analysis` | Brechas de informaci√≥n identificadas | Tipos de brechas, prioridad |
| `refinement` | Queries de refinamiento generadas | Cantidad de queries |
| `report_generation` | Generando reporte final | Cantidad de evidencia |
| `completed` | Investigaci√≥n completada | M√©tricas finales |
| `failed` | Error en la investigaci√≥n | Mensaje de error |

#### Ejemplo con Python (usando el script incluido):

```bash
# El script examples/deep_research.py ahora usa WebSocket autom√°ticamente
python examples/deep_research.py "Tu consulta de investigaci√≥n aqu√≠"
```

**Salida en tiempo real:**
```
3Ô∏è‚É£  Monitoreando progreso en tiempo real (esto puede tomar varios minutos)...
   üì° Usando WebSocket para actualizaciones instant√°neas... (Ctrl+C para cancelar)

   üì° Conectando a WebSocket: ws://localhost:8000/ws/progress/{task_id}
   ‚úÖ WebSocket conectado - recibiendo actualizaciones en tiempo real

   üöÄ [0.1s] Starting deep research: Tu consulta aqu√≠
   üìã [2.3s] Research plan created with 5 sub-tasks
   üîÑ [2.5s] Starting iteration 1/3
   üîç [15.2s] Collected 12 new evidence items (total: 12)
   üìä [16.1s] Completion score: 45% (PRELIMINARY)
      ‚îî‚îÄ Score: 0.45
   üéØ [17.8s] Identified 3 information gaps
      ‚îî‚îÄ Top gaps: market_data, regulatory_info
   üîß [18.2s] Generated 4 refinement queries for next iteration
   üîÑ [18.5s] Starting iteration 2/3
   üîç [32.1s] Collected 8 new evidence items (total: 20)
   üìä [33.0s] Completion score: 78% (COMPREHENSIVE)
      ‚îî‚îÄ Score: 0.78
   üéØ [34.2s] Identified 2 information gaps
   üîß [34.5s] Generated 2 refinement queries for next iteration
   üîÑ [34.8s] Starting iteration 3/3
   üîç [45.3s] Collected 5 new evidence items (total: 25)
   üìä [46.1s] Completion score: 92% (COMPREHENSIVE)
      ‚îî‚îÄ Score: 0.92
   üìù [46.5s] Generating final report...
   ‚úÖ [52.3s] Deep research completed! 25 evidence items, quality score: 92%

‚úÖ Investigaci√≥n completada en 52.3s
```

#### Ejemplo con Python (c√≥digo personalizado):

```python
import asyncio
import json
import websockets

async def monitor_research(task_id: str):
    uri = f"ws://localhost:8000/ws/progress/{task_id}"

    async with websockets.connect(uri) as websocket:
        print("Conectado a WebSocket")

        while True:
            message = await websocket.recv()
            update = json.loads(message)

            event_type = update['event_type']
            message_text = update['message']
            data = update.get('data', {})

            print(f"[{event_type}] {message_text}")

            if event_type == 'completed':
                print("¬°Investigaci√≥n completada!")
                break
            elif event_type == 'failed':
                print(f"Error: {data}")
                break

# Uso
task_id = "your-task-id-here"
asyncio.run(monitor_research(task_id))
```

#### Ejemplo con JavaScript/Node.js:

```javascript
const WebSocket = require('ws');

const taskId = 'your-task-id-here';
const ws = new WebSocket(`ws://localhost:8000/ws/progress/${taskId}`);

ws.on('open', () => {
    console.log('Conectado a WebSocket');
});

ws.on('message', (data) => {
    const update = JSON.parse(data);
    console.log(`[${update.event_type}] ${update.message}`);

    if (update.event_type === 'completed') {
        console.log('¬°Investigaci√≥n completada!');
        ws.close();
    }
});

ws.on('error', (error) => {
    console.error('Error:', error);
});
```

#### Fallback Autom√°tico:

Si el WebSocket falla por cualquier raz√≥n, el script autom√°ticamente vuelve al m√©todo tradicional de polling HTTP.

---

### üìä Monitoreo y Consulta de Investigaciones

#### üîç Monitorear Status en Tiempo Real

##### Research Simple - Polling HTTP

```bash
# 1. Iniciar investigaci√≥n
RESPONSE=$(curl -s -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{"query": "Tu consulta aqu√≠"}')

TASK_ID=$(echo $RESPONSE | jq -r '.task_id')
echo "Task ID: $TASK_ID"

# 2. Monitorear status mientras se ejecuta (cada 3 segundos)
while true; do
  STATUS=$(curl -s "http://localhost:8000/tasks/$TASK_ID/status" | jq -r '.status')
  echo "[$(date +%H:%M:%S)] Status: $STATUS"

  if [ "$STATUS" = "completed" ]; then
    echo "‚úÖ Investigaci√≥n completada!"
    break
  elif [ "$STATUS" = "failed" ]; then
    echo "‚ùå Investigaci√≥n fall√≥"
    break
  fi

  sleep 3
done

# 3. Obtener reporte
curl -s "http://localhost:8000/reports/$TASK_ID" | jq -r '.report_md' > reporte.md
echo "Reporte guardado en reporte.md"
```

##### Deep Research - WebSocket (Tiempo Real)

```bash
# Opci√≥n 1: Usar script Python (RECOMENDADO)
python examples/deep_research.py "Tu consulta aqu√≠"

# Ver√°s actualizaciones en tiempo real como:
# üöÄ [0.1s] Starting deep research...
# üìã [2.3s] Research plan created with 5 sub-tasks
# üîÑ [2.5s] Starting iteration 1/3
# üîç [15.2s] Collected 12 new evidence items (total: 12)
# üìä [16.1s] Completion score: 45% (PRELIMINARY)
# ...
# ‚úÖ [52.3s] Deep research completed!
```

```bash
# Opci√≥n 2: Manual con websocat
# Instalar websocat: cargo install websocat

# 1. Iniciar deep research
RESPONSE=$(curl -s -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Tu consulta aqu√≠",
    "max_iterations": 3,
    "min_completion_score": 0.85
  }')

TASK_ID=$(echo $RESPONSE | jq -r '.task_id')

# 2. Conectar WebSocket en otro terminal
websocat "ws://localhost:8000/ws/progress/$TASK_ID"

# Salida JSON en tiempo real:
# {"task_id":"abc-123","event_type":"started","message":"Starting deep research..."}
# {"task_id":"abc-123","event_type":"planning","message":"Research plan created..."}
# {"task_id":"abc-123","event_type":"iteration","message":"Starting iteration 1/3"}
# ...
```

##### WebSocket con Python - Script Completo

```python
#!/usr/bin/env python3
"""Monitorear deep research con WebSocket."""

import asyncio
import websockets
import json
import requests

async def monitor_deep_research(task_id: str):
    """Monitorea el progreso de una investigaci√≥n profunda."""
    ws_url = f"ws://localhost:8000/ws/progress/{task_id}"

    print(f"üì° Conectando a WebSocket: {ws_url}")

    try:
        async with websockets.connect(ws_url, ping_interval=20) as websocket:
            print("‚úÖ Conectado - recibiendo actualizaciones...\n")

            while True:
                try:
                    # Recibir mensaje
                    message = await asyncio.wait_for(websocket.recv(), timeout=30)
                    update = json.loads(message)

                    # Mostrar evento con emoji
                    emoji_map = {
                        "started": "üöÄ",
                        "planning": "üìã",
                        "iteration": "üîÑ",
                        "evidence": "üîç",
                        "evaluation": "üìä",
                        "gap_analysis": "üéØ",
                        "refinement": "üîß",
                        "report_generation": "üìù",
                        "completed": "‚úÖ",
                        "failed": "‚ùå"
                    }

                    emoji = emoji_map.get(update['event_type'], "‚ÑπÔ∏è")
                    print(f"{emoji} {update['message']}")

                    # Mostrar datos adicionales si existen
                    if update.get('data'):
                        for key, value in update['data'].items():
                            print(f"   ‚îî‚îÄ {key}: {value}")

                    # Terminar si complet√≥ o fall√≥
                    if update['event_type'] in ['completed', 'failed']:
                        break

                except asyncio.TimeoutError:
                    # Enviar ping para mantener conexi√≥n
                    await websocket.send("ping")

    except websockets.exceptions.WebSocketException as e:
        print(f"‚ùå Error de WebSocket: {e}")
        print("üí° Tip: Verifica que la API est√© corriendo")

# Uso
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Uso: python monitor.py <task_id>")
        sys.exit(1)

    task_id = sys.argv[1]
    asyncio.run(monitor_deep_research(task_id))
```

**Guardar como `tools/monitor_websocket.py` y usar:**

```bash
# Terminal 1: Iniciar investigaci√≥n
RESPONSE=$(curl -s -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{"query": "AI trends 2025"}')
TASK_ID=$(echo $RESPONSE | jq -r '.task_id')

# Terminal 2: Monitorear
python tools/monitor_websocket.py $TASK_ID
```

---

### üì• C√≥mo Obtener Reportes

Una vez que una investigaci√≥n se completa, puedes obtener el reporte de varias formas:

#### Opci√≥n 1: Obtener Reporte de Research Simple

```bash
# 1. Iniciar investigaci√≥n y guardar task_id
RESPONSE=$(curl -s -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{"query": "√öltimas tendencias en IA 2025"}')

TASK_ID=$(echo $RESPONSE | jq -r '.task_id')
echo "Task ID: $TASK_ID"

# 2. Esperar ~30-60 segundos para que complete

# 3. Obtener reporte completo
curl -s "http://localhost:8000/reports/$TASK_ID" | jq

# 4. Obtener solo el contenido del reporte en Markdown
curl -s "http://localhost:8000/reports/$TASK_ID" | jq -r '.report_md'

# 5. Guardar reporte en archivo
curl -s "http://localhost:8000/reports/$TASK_ID" | jq -r '.report_md' > report.md
echo "Reporte guardado en report.md"

# 6. Ver fuentes consultadas
curl -s "http://localhost:8000/reports/$TASK_ID" | jq -r '.sources_bib'
```

**Respuesta esperada:**
```json
{
  "status": "completed",
  "report_md": "# √öltimas Tendencias en IA 2025\n\n## Resumen Ejecutivo\n...",
  "sources_bib": "Generated from 15 evidence sources",
  "metrics_json": "{\"mock_metric\": 1.0}"
}
```

#### Opci√≥n 2: Obtener Reporte de Deep Research

```bash
# 1. Iniciar deep research y guardar task_id
RESPONSE=$(curl -s -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Impacto de la regulaci√≥n AI Act en startups europeas",
    "max_iterations": 3,
    "min_completion_score": 0.85
  }')

TASK_ID=$(echo $RESPONSE | jq -r '.task_id')
echo "Task ID: $TASK_ID"

# 2. Monitorear con WebSocket en tiempo real (en otro terminal)
# python examples/deep_research.py usa WebSocket autom√°ticamente

# O usar websocat (herramienta CLI para WebSocket)
websocat "ws://localhost:8000/ws/progress/$TASK_ID"

# 3. Obtener reporte completo con m√©tricas
curl -s "http://localhost:8000/deep-research/$TASK_ID" | jq

# 4. Obtener solo el contenido del reporte
curl -s "http://localhost:8000/deep-research/$TASK_ID" | jq -r '.report_md'

# 5. Guardar reporte completo en archivo
curl -s "http://localhost:8000/deep-research/$TASK_ID" | jq -r '.report_md' > deep_research_report.md

# 6. Ver m√©tricas de calidad
curl -s "http://localhost:8000/deep-research/$TASK_ID" | jq '.quality_metrics'

# 7. Ver resumen de investigaci√≥n
curl -s "http://localhost:8000/deep-research/$TASK_ID" | jq '.research_summary'
```

**Respuesta esperada:**
```json
{
  "status": "completed",
  "report_md": "# Impacto de AI Act en Startups Europeas\n\n## An√°lisis Profundo\n...",
  "sources_bib": "Generated from 42 evidence sources",
  "research_summary": {
    "iterations": 3,
    "total_evidence": 42,
    "quality_score": 0.88,
    "completion_level": "COMPREHENSIVE",
    "execution_time": 127.3
  },
  "quality_metrics": {
    "completion_level": "COMPREHENSIVE",
    "quality_score": 0.88,
    "evidence_count": 42,
    "execution_time": 127.3
  }
}
```

#### Opci√≥n 3: Monitorear Progreso con WebSocket (CLI)

Si tienes `websocat` instalado:

```bash
# Instalar websocat (opcional)
# cargo install websocat
# O descargar desde: https://github.com/vi/websocat/releases

# Iniciar deep research
RESPONSE=$(curl -s -X POST "http://localhost:8000/deep-research" \
  -H "Content-Type: application/json" \
  -d '{"query": "Tu consulta aqu√≠"}')
TASK_ID=$(echo $RESPONSE | jq -r '.task_id')

# Conectar a WebSocket y ver actualizaciones en tiempo real
websocat "ws://localhost:8000/ws/progress/$TASK_ID"

# Salida en tiempo real:
# {"task_id":"abc-123","timestamp":"2025-10-22T...","event_type":"started","message":"Starting deep research..."}
# {"task_id":"abc-123","timestamp":"2025-10-22T...","event_type":"planning","message":"Research plan created with 5 sub-tasks"}
# {"task_id":"abc-123","timestamp":"2025-10-22T...","event_type":"iteration","message":"Starting iteration 1/3"}
# ...
```

#### Opci√≥n 4: Obtener Reportes desde MongoDB

Si tienes MongoDB configurado, puedes consultar reportes directamente:

```bash
# Conectar a MongoDB
docker exec -it aletheia-mongodb mongosh \
  -u aletheia -p aletheia_password \
  --authenticationDatabase admin \
  aletheia

# Comandos dentro de mongosh:

# Ver todas las tareas completadas
db.tasks.find({status: "completed"}).pretty()

# Obtener reporte por task_id
db.reports.findOne({task_id: "abc-123-def-456"})

# Ver los √∫ltimos 5 reportes generados
db.reports.find().sort({created_at: -1}).limit(5).pretty()

# Exportar reporte a archivo
db.reports.findOne({task_id: "abc-123-def-456"}, {content: 1}) | jq -r '.content' > report.md

# Buscar reportes por palabra clave en la consulta
db.reports.find({query: /inteligencia artificial/i}).pretty()

# Obtener reportes de deep research solamente
db.reports.find({type: "deep_research"}).pretty()

# Ver estad√≠sticas de reportes
db.reports.aggregate([
  {$group: {
    _id: "$type",
    count: {$sum: 1}
  }}
])
```

#### Opci√≥n 5: Script Python para Obtener Reportes

```python
#!/usr/bin/env python3
"""Script para obtener y guardar reportes."""
import requests
import sys
from datetime import datetime

def get_report(task_id: str, report_type: str = "research"):
    """Obtiene un reporte y lo guarda en archivo."""

    # Determinar endpoint
    if report_type == "deep_research":
        url = f"http://localhost:8000/deep-research/{task_id}"
    else:
        url = f"http://localhost:8000/reports/{task_id}"

    # Obtener reporte
    response = requests.get(url)
    response.raise_for_status()
    data = response.json()

    if data.get("status") != "completed":
        print(f"‚ùå Reporte no completado. Status: {data.get('status')}")
        return

    # Extraer contenido
    report_md = data.get("report_md", "")

    if not report_md:
        print("‚ùå Reporte vac√≠o")
        return

    # Guardar en archivo
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"report_{task_id[:8]}_{timestamp}.md"

    with open(filename, "w", encoding="utf-8") as f:
        f.write(report_md)

    print(f"‚úÖ Reporte guardado en: {filename}")
    print(f"   Longitud: {len(report_md)} caracteres")

    if report_type == "deep_research":
        metrics = data.get("quality_metrics", {})
        print(f"   Quality Score: {metrics.get('quality_score', 0):.2%}")
        print(f"   Evidence Count: {metrics.get('evidence_count', 0)}")

# Uso
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Uso: python get_report.py <task_id> [research|deep_research]")
        sys.exit(1)

    task_id = sys.argv[1]
    report_type = sys.argv[2] if len(sys.argv) > 2 else "research"

    get_report(task_id, report_type)
```

**Uso del script:**
```bash
# Guardar como tools/get_report.py
python tools/get_report.py abc-123-def-456 research
python tools/get_report.py xyz-789-ghi-012 deep_research
```

#### Opci√≥n 6: Listar Todas las Tareas Disponibles

```bash
# Si tienes MongoDB configurado
docker exec -it aletheia-mongodb mongosh \
  -u aletheia -p aletheia_password \
  --authenticationDatabase admin \
  aletheia \
  --eval "db.tasks.find({}, {task_id: 1, query: 1, status: 1, created_at: 1}).sort({created_at: -1}).limit(10).forEach(printjson)"

# Salida:
# {
#   "_id": ObjectId("..."),
#   "task_id": "abc-123-def-456",
#   "query": "√öltimas tendencias en IA 2025",
#   "status": "completed",
#   "created_at": ISODate("2025-10-22T15:30:00Z")
# }
# ...
```

#### Consejos para Obtener Reportes:

- ‚úÖ **Guarda el task_id** inmediatamente despu√©s de iniciar una investigaci√≥n
- ‚úÖ **Espera a que complete** antes de obtener el reporte (status = "completed")
- ‚úÖ **Usa WebSocket** para monitoreo en tiempo real durante deep research
- ‚úÖ **Configura MongoDB** para persistencia de reportes entre reinicios
- ‚úÖ **Exporta a archivos** los reportes importantes para backup

---

### üîç Monitoreo de Tareas (M√©todo Tradicional)

#### Workflow completo con bash

```bash
#!/bin/bash
# Script para ejecutar y monitorear una investigaci√≥n

# 1. Iniciar investigaci√≥n
RESPONSE=$(curl -s -X POST "http://localhost:8000/research" \
  -H "Content-Type: application/json" \
  -d '{"query": "Tu consulta aqu√≠"}')

# 2. Extraer task_id
TASK_ID=$(echo $RESPONSE | jq -r '.task_id')
echo "Task ID: $TASK_ID"

# 3. Monitorear estado
while true; do
  STATUS=$(curl -s "http://localhost:8000/tasks/$TASK_ID/status" | jq -r '.status')
  echo "Status: $STATUS"

  if [ "$STATUS" == "completed" ]; then
    break
  fi

  sleep 5
done

# 4. Obtener reporte
curl -s "http://localhost:8000/reports/$TASK_ID" | jq -r '.report_md' > report.md
echo "Reporte guardado en report.md"
```

### üìä Respuestas de la API

#### Formato de Reporte de Investigaci√≥n Simple

```json
{
  "status": "completed",
  "report_md": "# T√≠tulo del Reporte\n\n## Resumen Ejecutivo\n...",
  "sources_bib": "Generated from 15 evidence sources",
  "metrics_json": "{\"mock_metric\": 1.0}"
}
```

#### Formato de Reporte de Deep Research

```json
{
  "status": "completed",
  "report_md": "# An√°lisis Profundo\n\n...",
  "sources_bib": "Generated from 42 evidence sources",
  "research_summary": {
    "iterations_completed": 3,
    "gaps_identified": ["regulatory_compliance", "market_impact"],
    "key_findings": [
      "High compliance costs",
      "Market consolidation likely"
    ]
  },
  "quality_metrics": {
    "completion_level": 0.95,
    "quality_score": 0.88,
    "evidence_count": 42,
    "execution_time": 127.3
  }
}
```

### üõ† Testing y Troubleshooting

#### Test R√°pido de APIs

```bash
# Ejecutar suite de tests
python3 tools/testing/test_apis.py

# Test individual de Saptiva
python3 tools/testing/test_saptiva_direct.py
```

#### Problemas Comunes

##### üîë Problemas con API Keys

**Error: "API key not configured"**
```bash
# Verificar que las keys est√©n configuradas
cat .env | grep API_KEY

# Deben estar presentes y no contener valores placeholder
SAPTIVA_API_KEY=va-ai-...  # Debe empezar con 'va-ai-'
TAVILY_API_KEY=tvly-...    # Debe empezar con 'tvly-'
```

**Error: Modelos retornan 404 "Model not found"**
```bash
# Verificar que los nombres de modelos usen capitalizaci√≥n correcta
# ‚ùå INCORRECTO:
SAPTIVA_MODEL_PLANNER=SAPTIVA_OPS

# ‚úÖ CORRECTO:
SAPTIVA_MODEL_PLANNER=Saptiva Ops
```

**Error: "URL incorrecta" o conexiones fallando**
```bash
# Verificar que uses .com NO .ai
# ‚ùå INCORRECTO:
SAPTIVA_BASE_URL=https://api.saptiva.ai/v1

# ‚úÖ CORRECTO:
SAPTIVA_BASE_URL=https://api.saptiva.com/v1
```

##### üíæ Problemas con MongoDB

**Error: "Task not found" despu√©s de crear tarea**
```bash
# Problema: MongoDB no est√° conectado o m√∫ltiples workers sin DB compartida

# Soluci√≥n 1: Verificar conexi√≥n MongoDB (modo Docker)
docker logs aletheia-mongodb
docker exec aletheia-mongodb mongosh --eval "db.adminCommand('ping')"

# Soluci√≥n 2: Verificar que API se conect√≥ a MongoDB
docker logs aletheia-api | grep MongoDB
# Debe mostrar: "‚úÖ MongoDB initialized: aletheia"

# Soluci√≥n 3: Si usas modo local sin MongoDB, es normal
# Las tareas se pierden al reiniciar (modo en memoria)
```

**Error: "Port 27017 already allocated"**
```bash
# Problema: Otro servicio MongoDB corriendo en puerto 27017

# Soluci√≥n: El proyecto usa puerto 27018 por defecto
# Verificar en .env:
MONGO_PORT=27018  # No 27017

# Si a√∫n falla:
docker ps -a | grep mongo
docker stop <otro-contenedor-mongo>
```

**Error: "Failed to initialize MongoDB"**
```bash
# Verificar que MongoDB est√© saludable
docker ps | grep aletheia-mongodb
# STATUS debe ser "healthy"

# Ver logs de MongoDB
docker logs aletheia-mongodb

# Reiniciar MongoDB
docker-compose restart mongodb

# Si persiste, recrear vol√∫menes
docker-compose down -v
docker-compose up -d
```

**Verificar datos en MongoDB**
```bash
# Conectar a MongoDB y ver datos
docker exec aletheia-mongodb mongosh \
  -u aletheia -p aletheia_password \
  --authenticationDatabase admin \
  aletheia

# Comandos dentro de mongosh:
db.tasks.find().pretty()    # Ver tareas
db.reports.find().count()   # Contar reportes
db.logs.find().limit(5)     # Ver √∫ltimos 5 logs
```

##### üåê Problemas de Red y Conectividad

**Error: "Timeout" o "Connection Error"**
```bash
# Verificar configuraci√≥n de timeouts en .env
SAPTIVA_CONNECT_TIMEOUT=30
SAPTIVA_READ_TIMEOUT=120
```

**La API no responde**
```bash
# Modo Docker:
curl http://localhost:8000/health
docker logs aletheia-api

# Modo Local:
# Verificar que el servidor est√© corriendo
curl http://localhost:8000/health

# Si no responde, iniciar servidor
uvicorn apps.api.main:app --reload
```

##### üê≥ Problemas con Docker

**Error: "Container unhealthy"**
```bash
# Ver qu√© est√° fallando
docker ps
docker logs aletheia-api --tail 50

# Verificar health check
docker inspect aletheia-api | grep -A 10 Health

# Reiniciar contenedor
docker-compose restart api
```

**Error: "Build failed" o dependencias faltantes**
```bash
# Rebuild sin cach√©
docker-compose build --no-cache

# Verificar que pymongo y motor est√©n en requirements.txt
cat requirements.txt | grep -E "pymongo|motor"
```

##### üîÑ Problemas de Persistencia

**Las tareas desaparecen al reiniciar**
```bash
# Problema: Modo en memoria (sin MongoDB)

# Soluci√≥n: Usar Docker Compose con MongoDB
docker-compose up -d

# O configurar MongoDB local
# Instalar MongoDB: https://www.mongodb.com/docs/manual/installation/
# Configurar en .env:
MONGODB_URL=mongodb://localhost:27017
MONGODB_DATABASE=aletheia
```

**Datos antiguos permanecen despu√©s de reiniciar**
```bash
# Esto es CORRECTO si usas MongoDB
# Los datos persisten en vol√∫menes de Docker

# Para limpiar datos y empezar de cero:
docker-compose down -v  # -v elimina vol√∫menes
docker-compose up -d    # Inicia limpio
```

---

## üèó Arquitectura

### Vista general

```mermaid
flowchart TB
    subgraph API[FastAPI Application]
        E[Endpoints]
        M[Middleware]
        H[Health Checks]
    end

    subgraph Domain[Domain Layer]
        T[ResearchTask]
        Plan[Planning Service]
        Research[Research Service]
        Eval[Evaluation Service]
        Orchestrator[Iterative Orchestrator]
        Writer[Writer Service]
    end

    subgraph Ports[Port Interfaces]
        ModelPort[Model Client Port]
        SearchPort[Search Port]
        DatabasePort[Database Port]
        VectorPort[Vector Store Port]
        ExtractPort[Document Extract Port]
        GuardPort[Guard Port]
    end

    subgraph Adapters[External Integrations]
        Saptiva[Saptiva AI Models]
        Tavily[Tavily Search API]
        MongoDB[MongoDB Database]
        Weaviate[Weaviate Vector DB]
        PDFExtract[PDF/OCR Extractor]
        Telemetry[OpenTelemetry]
    end

    API --> Domain
    Domain --> Ports
    Ports --> Adapters
```

### Flujo de investigaci√≥n


```mermaid
flowchart TD
    A[Query Input] --> B[Query Normalization]
    B --> C[Planning Service]
    C --> D[Subtask Generation]
    D --> E[Parallel Research Execution]
    
    E --> F[Tavily Search]
    E --> G[Web Scraping]
    E --> H[Document Extraction]
    
    F --> I[Evidence Collection]
    G --> I
    H --> I
    
    I --> J[Quality Scoring]
    J --> K[Vector Embedding]
    K --> L[Weaviate Storage]
    
    L --> M[Evidence Clustering]
    M --> N[Completeness Evaluation]
    
    N --> O{Quality Threshold Met?}
    O -->|No| P[Gap Analysis]
    O -->|Yes| Q[Report Synthesis]
    
    P --> R[Refinement Queries]
    R --> E
    
    Q --> S[Citation Generation]
    S --> T[Final Report]
    T --> U[Artifact Export]
    
    subgraph "Quality Control"
        V[Authority Scoring]
        W[Recency Weighting]
        X[Relevance Ranking]
        Y[Bias Detection]
    end
    
    J --> V
    J --> W
    J --> X
    J --> Y
```


### Principios de dise√±o

- **üèõ Clean Architecture**: Separaci√≥n clara entre dominio, puertos y adapters
- **üîå Dependency Inversion**: Abstracciones estables, implementaciones intercambiables
- **üß™ Testability**: 99 unit tests, mocking de dependencias externas
- **‚ö° Performance**: Procesamiento paralelo, optimizaciones as√≠ncronas
- **üõ° Resilience**: Graceful degradation, retry mechanisms, modo fallback
- **üéØ Simplicity**: Configuraci√≥n minimalista, servicios externos opcionales

**Modo Minimalista por defecto:**
- Vector storage opera en modo mock (sin Weaviate)
- Evidence se almacena en memoria durante la sesi√≥n
- No hay impacto en rendimiento del pipeline de investigaci√≥n
- Todas las funcionalidades operan normalmente

---

## üîß Desarrollo

### Estructura del proyecto

```
alethia_deepresearch/
‚îú‚îÄ‚îÄ apps/                    # FastAPI application
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îú‚îÄ‚îÄ domain/                  # Business logic (clean architecture)
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Domain models
‚îÇ   ‚îî‚îÄ‚îÄ services/           # Domain services
‚îú‚îÄ‚îÄ adapters/               # External integrations
‚îÇ   ‚îú‚îÄ‚îÄ mongodb/            # MongoDB database adapter
‚îÇ   ‚îú‚îÄ‚îÄ saptiva_model/      # Saptiva AI integration
‚îÇ   ‚îú‚îÄ‚îÄ tavily_search/      # Tavily search integration
‚îÇ   ‚îú‚îÄ‚îÄ weaviate_vector/    # Vector database
‚îÇ   ‚îî‚îÄ‚îÄ telemetry/          # Observability
‚îú‚îÄ‚îÄ ports/                  # Interface contracts
‚îÇ   ‚îú‚îÄ‚îÄ database_port.py    # Database abstraction
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ tests/                  # Test suites
‚îÇ   ‚îú‚îÄ‚îÄ unit/              # Unit tests (99 tests)
‚îÇ   ‚îî‚îÄ‚îÄ integration/       # Integration tests
‚îú‚îÄ‚îÄ scripts/               # Deployment & utility scripts
‚îÇ   ‚îî‚îÄ‚îÄ deployment/        # Deployment automation
‚îú‚îÄ‚îÄ infra/                 # Infrastructure as code
‚îÇ   ‚îú‚îÄ‚îÄ docker/           # Docker Compose
‚îÇ   ‚îî‚îÄ‚îÄ k8s/              # Kubernetes manifests
‚îî‚îÄ‚îÄ docs/                  # Documentation
```

### Scripts disponibles

```bash
# Verificaci√≥n de Python
./scripts/check_python_version.sh      # Verificar Python 3.11+

# Deployment scripts
./scripts/deployment/setup-server.sh   # Configurar servidor remoto
./scripts/deployment/deploy-remote.sh  # Deploy via SSH
./scripts/deployment/deploy-docker.sh  # Deploy con Docker local
./scripts/deployment/deploy.sh         # Deploy general
```

### Configuraci√≥n de desarrollo

```bash
# Pre-commit hooks (recomendado)
pip install pre-commit
pre-commit install

# Variables de desarrollo
export DEBUG=true
export LOG_LEVEL=DEBUG
export ENVIRONMENT=development
```

---

## üíæ MongoDB: Almacenamiento Persistente

### Caracter√≠sticas

Aletheia usa MongoDB para almacenamiento persistente de:
- **Tasks**: Estado de investigaciones (accepted, running, completed, failed)
- **Reports**: Reportes completos en formato Markdown
- **Logs**: Registro de eventos y errores con timestamps

### Colecciones

#### üìã Collection: `tasks`
```javascript
{
  "_id": ObjectId("..."),
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "query": "An√°lisis del mercado de IA 2025",
  "type": "research",  // o "deep_research"
  "evidence_count": 15,
  "sources": "Generated from 15 evidence sources",
  "created_at": ISODate("2025-01-15T10:00:00Z"),
  "updated_at": ISODate("2025-01-15T10:01:30Z"),
  "started_at": 1737799200.123
}
```

**√çndices creados:**
- `task_id` (√∫nico)
- `status`
- `created_at`

#### üìÑ Collection: `reports`
```javascript
{
  "_id": ObjectId("..."),
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "content": "# An√°lisis del Mercado de IA 2025\n\n## Resumen Ejecutivo...",
  "query": "An√°lisis del mercado de IA 2025",
  "type": "research",  // o "deep_research"
  "summary": {...},     // Solo para deep_research
  "created_at": ISODate("2025-01-15T10:01:30Z"),
  "updated_at": ISODate("2025-01-15T10:01:30Z")
}
```

**√çndices creados:**
- `task_id` (√∫nico)
- `created_at`

#### üìù Collection: `logs`
```javascript
{
  "_id": ObjectId("..."),
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "level": "INFO",  // DEBUG, INFO, WARNING, ERROR, CRITICAL
  "message": "Research completed successfully with 15 evidence sources",
  "timestamp": ISODate("2025-01-15T10:01:30Z")
}
```

**√çndices creados:**
- `task_id`
- `level`
- `timestamp`

### Consultas √ötiles

```bash
# Conectar a MongoDB
docker exec -it aletheia-mongodb mongosh \
  -u aletheia -p aletheia_password \
  --authenticationDatabase admin \
  aletheia

# Ver estad√≠sticas
db.tasks.countDocuments()
db.reports.countDocuments()
db.logs.countDocuments()

# Tareas por estado
db.tasks.aggregate([
  { $group: { _id: "$status", count: { $sum: 1 } } }
])

# √öltimas 5 investigaciones completadas
db.tasks.find(
  { status: "completed" }
).sort({ created_at: -1 }).limit(5).pretty()

# Reportes m√°s recientes
db.reports.find(
  {},
  { content: 0 }  // Excluir contenido largo
).sort({ created_at: -1 }).limit(5).pretty()

# Logs de errores
db.logs.find(
  { level: "ERROR" }
).sort({ timestamp: -1 }).limit(10).pretty()

# Logs de una tarea espec√≠fica
db.logs.find(
  { task_id: "550e8400-e29b-41d4-a716-446655440000" }
).sort({ timestamp: 1 }).pretty()

# Eliminar tareas antiguas (> 30 d√≠as)
db.tasks.deleteMany({
  created_at: {
    $lt: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000)
  }
})

# Backup de una colecci√≥n
db.tasks.find().forEach(function(doc) {
  printjson(doc);
})
```

### Modo Fallback (Sin MongoDB)

Si MongoDB no est√° disponible, la API opera en **modo fallback**:

```
üìù No MongoDB URL configured, using in-memory storage
```

**Caracter√≠sticas del modo fallback:**
- ‚úÖ Todas las funcionalidades operan normalmente
- ‚úÖ Perfecto para desarrollo y testing
- ‚ö†Ô∏è Los datos se pierden al reiniciar el servidor
- ‚ö†Ô∏è No soporta m√∫ltiples workers (usa --workers 1)

**Cu√°ndo usar modo fallback:**
- Desarrollo local r√°pido
- Testing unitario
- Demos temporales

**Cu√°ndo usar MongoDB:**
- Producci√≥n
- M√∫ltiples workers
- Necesidad de persistencia
- Auditor√≠a y logs hist√≥ricos

### Configuraci√≥n de MongoDB Local

Si quieres usar MongoDB localmente sin Docker:

```bash
# 1. Instalar MongoDB
# Ubuntu/Debian:
wget -qO - https://www.mongodb.org/static/pgp/server-7.0.asc | sudo apt-key add -
echo "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list
sudo apt update && sudo apt install -y mongodb-org

# macOS:
brew tap mongodb/brew
brew install mongodb-community@7.0

# 2. Iniciar MongoDB
sudo systemctl start mongod  # Linux
brew services start mongodb-community@7.0  # macOS

# 3. Configurar en .env
MONGODB_URL=mongodb://localhost:27017
MONGODB_DATABASE=aletheia

# 4. Reiniciar API
uvicorn apps.api.main:app --reload
```

### Backup y Restore

```bash
# Backup completo
docker exec aletheia-mongodb mongodump \
  --username=aletheia \
  --password=aletheia_password \
  --authenticationDatabase=admin \
  --db=aletheia \
  --out=/backup

# Copiar backup al host
docker cp aletheia-mongodb:/backup ./mongodb-backup

# Restore
docker exec aletheia-mongodb mongorestore \
  --username=aletheia \
  --password=aletheia_password \
  --authenticationDatabase=admin \
  --db=aletheia \
  /backup/aletheia
```

---

## üìä Monitoreo y Observabilidad

### Health Check

El endpoint de salud proporciona informaci√≥n completa del sistema:

```bash
curl http://localhost:8000/health
```

**Respuesta:**
```json
{
  "status": "healthy",
  "service": "Aletheia Deep Research API",
  "version": "0.2.0",
  "api_keys": {
    "saptiva_available": true,
    "tavily_available": true
  }
}
```

### Logs Estructurados

El sistema incluye logging completo sin dependencias externas:

- **Formato**: Console output estructurado (JSON opcional)
- **Niveles**: DEBUG, INFO, WARNING, ERROR
- **Task IDs**: Tracking autom√°tico de todas las requests
- **Timestamps**: Informaci√≥n temporal precisa

### Observabilidad Avanzada (100% Opcional)

Si necesitas trazabilidad distribuida o m√©tricas detalladas:

```bash
# 1. Instalar dependencias opcionales
pip install -r requirements-optional.txt

# 2. Habilitar servicios en docker-compose.yml
# (Descomentar secciones de Jaeger/OpenTelemetry)

# 3. Configurar en .env
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
```

**Nota**: La configuraci√≥n minimalista incluye OpenTelemetry b√°sico sin servicios externos.

---

## ü§ù Contribuir

### Workflow de desarrollo

1. **Fork** el repositorio
2. **Crear branch** para feature/fix: `git checkout -b feature/amazing-feature`
3. **Commit** cambios: `git commit -m 'Add amazing feature'`
4. **Push** a branch: `git push origin feature/amazing-feature`
5. **Crear Pull Request**

### Est√°ndares de c√≥digo

- ‚úÖ **Linting**: C√≥digo debe pasar `ruff check`
- ‚úÖ **Format**: Usar `ruff check --fix` para auto-format
- ‚úÖ **Types**: Type hints obligatorios
- ‚úÖ **Tests**: Tests unitarios para nuevas features
- ‚úÖ **Docs**: Actualizar README.md si es necesario

### Revisi√≥n de c√≥digo

- CI/CD debe pasar (99 tests, linting, security)
- Revisi√≥n por al menos 1 maintainer
- Documentaci√≥n actualizada si aplica

---

## üìö Recursos Adicionales

### Documentaci√≥n

- **[API Reference](http://localhost:8000/docs)**: Swagger UI interactivo con ejemplos
- **[ReDoc](http://localhost:8000/redoc)**: Documentaci√≥n alternativa de la API
- **[Documentaci√≥n t√©cnica](docs/)**: Gu√≠as detalladas y ejemplos en el directorio docs/
- **[SIMPLIFICATION.md](SIMPLIFICATION.md)**: Gu√≠a de la configuraci√≥n minimalista

### Enlaces √ötiles

- **[GitHub Issues](https://github.com/saptiva-ai/alethia_deepresearch/issues)**: Reportar bugs o solicitar features
- **[GitHub Discussions](https://github.com/saptiva-ai/alethia_deepresearch/discussions)**: Preguntas y discusiones
- **[Releases](https://github.com/saptiva-ai/alethia_deepresearch/releases)**: Historial de versiones

---

## üìÑ Licencia

Apache License 2.0 - ver [LICENSE](LICENSE) para m√°s detalles.

Copyright 2025 Saptiva Inc.

---

## üôè Agradecimientos

- **Saptiva AI** - Modelos de lenguaje de vanguardia
- **Tavily** - Search API para investigaci√≥n
- **FastAPI** - Framework web moderno y r√°pido
- **MongoDB** - Base de datos NoSQL para persistencia
- **Weaviate** - Vector database escalable

---

<div align="center">

**¬øEncontraste √∫til este proyecto? ‚≠ê Danos una estrella!**

[Reportar Bug](https://github.com/saptiva-ai/alethia_deepresearch/issues) ¬∑ [Solicitar Feature](https://github.com/saptiva-ai/alethia_deepresearch/issues) ¬∑ [Documentaci√≥n](docs/)

</div>
